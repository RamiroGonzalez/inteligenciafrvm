{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción al Aprendizaje Supervisado - Clasificación (Parte II)\n",
    "\n",
    "* Pre-procesamiento de los datos.\n",
    "* Evaluación de un clasificador.\n",
    "* FPR vs FNR tradeoff.\n",
    "\n",
    "5to año - Ingeniería en Sistemas de Información\n",
    "\n",
    "Facultad Regional Villa María"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-procesamiento de datos\n",
    "\n",
    "Un problema muy frecuente (en industria es uno de los problemas más reportados en ML) es que los datasets \"crudos\" no pueden recibir entrenamiento tal como están, por lo que necesitan un pre-procesamiento para poder adaptarse a los requerimientos del modelo. Vemos algunos métodos de pre-procesamiento comunes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de features que no aportan a la predicción\n",
    "\n",
    "Un problema común en los datasets es que muchas veces los mismos tienen algunas variables que no están relacionadas de ninguna forma con las salidas o bien es sabido a priori que no aportan información significativa para predecir la salida.\n",
    "\n",
    "* Un ejemplo común son los identificadores, los cuales asocian cada fila de datos con un único código de identificación.\n",
    "\n",
    "* Estos features deben eliminarse, porque de lo contrario el modelo los ajustará e intentará hacer predicciones con datos que no tienen aporte alguno, empeorando la calidad general del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ampliación o transformación del dataset\n",
    "\n",
    "De forma similar, existen maneras de agregar o transformar datos en el dataset para mejorar las predicciones, por ejemplo incorporando información de datasets públicos o generando nuevos features a partir de los existentes o con la ayuda de información de dominio.\n",
    "\n",
    "* Este tipo de mejoras puede ayudar a mejorar las predicciones del dataset, por ejemplo al poder utilizar features más relevantes para predecir las salidas.\n",
    "\n",
    "* Al igual que al eliminar los features (más allá de aquellos obvios como los identificadores), no hay una regla general para ampliar el dataset, pues depende mucho del dominio del problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy variables para datasets con features no numéricos\n",
    "\n",
    "* Por ejemplo, si tenemos que hacer una predicción sobre imágenes geométricas y contamos con una variable categórica \"Color\" en las mismas que toma valores \"Rojo\", \"Azul\" y \"Verde\". Tal variable no puede ser utilizada de esa forma para hacer la predicción, puesto que los modelos emplean features numéricos.\n",
    "* Una solución rápida consistiría en reemplazar los features asignando, por ejemplo, 0 cuando se trata de \"Rojo\" , 1 cuando se trata de \"Azul\" y 2 cuando es \"Verde\", es decir\n",
    "\n",
    "|                 | Color  |\n",
    "|-----------------|:------:|        \n",
    "| Rectángulo rojo |    0   |\n",
    "| Círculo azul    |    1   |\n",
    "| Estrella verde  |    2   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El problema de este enfoque es que asumimos arbitrariamente un orden en los features, por lo cual nuestro modelo estaría innecesariamente sesgado en su entrenamiento, estableciendo por ejemplo que \"Verde\" es el doble que \"Azul\".\n",
    "* El enfoque utilizado para estos casos consiste en crear un nuevo feature para cada valor categórico posible, asignando un 1 cuando el valor pertenece a la mencionada categoría y un 0 para todas las demás categorías.\n",
    "* Esta transformación se conoce como \"one-hot encoding\", y las variables de esta forma reciben el nombre de \"dummy variable\".\n",
    "\n",
    "|                 | Rojo  | Azul  |Verde|\n",
    "|-----------------|:-----:|:-----:|:---:|\n",
    "| Rectángulo rojo |   1   |   0   |  0  |\n",
    "| Círculo azul    |   0   |   1   |  0  |\n",
    "| Estrella verde  |   0   |   0   |  1  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización de los datos\n",
    "\n",
    "En virtud de que todos los features **contribuyan de forma equitativa** (es decir que no tengan más peso en la clasificación aquellos features con mayor magnitud), para algunos modelos se requiere que los datos estén normalizados de alguna forma, por ejemplo para que todos los valores caigan en el mismo rango fijo. La normalización se hace en cada feature. Informalmente, \"para cada columna\".\n",
    "\n",
    "\n",
    "* Una normalización posible es **minmax normalization**, la cual transforma un feature de tal forma que todos sus valores caigan en el rango $[0,1]$.\n",
    "* Para lograr esto es suficiente hacer, para cada elemento $j$ del feature $X_i$\n",
    "\n",
    "$$Z_{ij} = \\frac{X_{ij} - min(X_{i})}{max(X_{i}) - min(X_{i})}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo: dados los siguientes datos,\n",
    "\n",
    "| Feature_1 |\n",
    "|:---------:|\n",
    "| 42        |\n",
    "| 66        |\n",
    "| 187       |\n",
    "| 29        |\n",
    "\n",
    "Normalizando...\n",
    "\n",
    "| Feature_1 |\n",
    "|:---------:|\n",
    "| 0.08      |\n",
    "| 0.23      |\n",
    "| 1         |\n",
    "| 0         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Otra normalización muy común es la **z-score standarization**, normaliza los valores con respecto a la desviación estándar, dejando los mismos con media 0. Analíticamente, $$Z_{ij} = \\frac{X_{ij} - \\bar{X}}{\\sigma}$$ donde $\\bar{X}$ es la media de la población y $\\sigma$ es la desviación estándar.\n",
    "\n",
    "* Cada valor $Z_{ij}$ normalizado representa la distancia entre el valor $X_{ij}$ y la media de la población, en $Z_{ij}$ desviaciones estándar como unidad.\n",
    "\n",
    "Normalizando los datos iniciales del ejemplo el ejemplo anterior...\n",
    "\n",
    "| Feature_1 |\n",
    "|:---------:|\n",
    "| 42        |\n",
    "| 66        |\n",
    "| 187       |\n",
    "| 29        |\n",
    "\n",
    "Media = 81;\n",
    "desviación estándar = 72.3\n",
    "\n",
    "| Feature_1 |\n",
    "|:---------:|\n",
    "|-0.62      |\n",
    "|-0.23      |\n",
    "| 1.69      |\n",
    "|-0.83      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué sucede cuando queremos normalizar y tenemos que dividir los datos en train y test (o, análogamente, en train y validation)?\n",
    "\n",
    "Si normalizamos toda nuestra matriz de datos X, tendremos un problema: estaremos sesgando indirectamente nuestro entrenamiento con respecto a los conjuntos de test y de validación.\n",
    "\n",
    "Lo que se hace en estos casos es:\n",
    "\n",
    "1. Obtener $\\bar{X}_{train}$ y $\\sigma_{train}$ para el caso de normalización z-score, o $min(X_i)_{train}$ y $max(X_i)_{train}$ para el caso de minmax.\n",
    "2. Aplicar la normalización al conjunto de entrenamiento.\n",
    "3. Al hacer predicciones, normalizar el conjunto de validación o test **con respecto a los estadísticos del conjunto de entrenamiento**, es decir $\\bar{X}_{train}$ y $\\sigma_{train}$ (para el caso de z-score). Es decir que para normalizar el conjunto de test, hacemos para cada uno de sus $X_{ij}$:\n",
    "\n",
    "$$Z_{ij} = \\frac{X_{ij} - \\bar{X}_{train}}{\\sigma_{train}}$$\n",
    "\n",
    "Naturalmente, si hacemos esto perderemos alguna de las propiedades de la normalización para el conjunto de test (por ejemplo, en el caso de z-score, es muy probable que la media y desviación de los datos de test difieran de 0 y 1, respectivamente), pero esto es totalmente preferible antes que sesgar el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluando un clasificador\n",
    "\n",
    "La forma más simple de evaluar un clasificador es mediante el porcentaje o **tasa de aciertos**, es decir qué porcentaje de nuestras predicciones predijeron correctamente la clase de todos los puntos consultados.\n",
    "\n",
    "* Retomamos el ejemplo de la clase pasada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 2 0 2 2 0 0 0 2 2 1 0 2 1 0 1 0 0 0 2 2 1 2 0 1 1 1 2 0 1 0 1 1 1 0\n",
      " 2 1 0 0 0 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target\n",
    "\n",
    "# Dividimos el conjunto en train, test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=80, test_size=0.3)\n",
    "\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_hat = clf.predict(X_test)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de aciertos en la clasificación:  0.7555555555555555\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de aciertos en la clasificación: ', clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Esta métrica es una buena medida para saber rápidamente los aciertos en todo clasificador. Sin embargo no nos está dando detalles como, por ejemplo, que todas las Setosas fueron correctamente clasificadas. Para ello vamos a usar mejor información, que incluya las métricas comúnmente utilizadas para evaluar un clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tipos de errores\n",
    "\n",
    "En la clasificación binaria (es decir cuando la cantidad de clases posibles a la que una variable puede pertenecer es de dos), al intentar hacer una predicción, existen dos tipos de errores de predicción a considerar.\n",
    "\n",
    "Por ejemplo, supongamos que testeamos la existencia de una enfermedad en un paciente. Como _hipótesis nula_ $h_0$ tomamos a \"$h_0$: el paciente no posee la enfermedad\", mientras que como _hipótesis alternativa_ tomamos \"$h_1$: el paciente posee la enfermedad\".\n",
    "\n",
    "* $h_0$ es la hipótesis que se suele usar para establecer **\"ausencia o inexistencia de relación entre dos fenómenos\"** (tomando como fenómenos el paciente y la enfermedad), mientras que $h_1$ representa **\"algún tipo de relación entre dos fenómenos\"**.\n",
    "\n",
    "* \"_Inocente hasta que se demuestre lo contrario_\". En testing de hipótesis, $h_0$ es la postura por defecto. Esto quiere decir que para rechazarla y por lo tanto validar una hipótesis alternativa debe demostrarse fehacientemente que $h_0$ es falsa más allá de toda duda razonable (normalmente representada por un intérvalo de confianza de 1% o 5%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El **error de tipo I**, **false positive** o **falsa alarma** ocurre cuando se rechaza incorrectamente una $h_0$ verdadera. En nuestro ejemplo, esto sucede cuando incorrectamente diagnosticamos la enfermedad en el paciente.\n",
    "\n",
    "* Por otra parte, el **error de tipo II**, **false negative** o **detección perdida**, ocurre cuando incorrectamente se retiene una $h_0$ falsa, siendo que se daba la relación establecida por $h_1$. En nuestro ejemplo esto sucede cuando detectamos incorrectamente que el paciente no registra la enfermedad.\n",
    "\n",
    "* En el caso de que la predicción haya sido correcta, decimos que la misma arrojó un **true positive** o **true negative**, según si se predijo correctamente la existencia o no de la relación entre dos fenómenos (_positive_ significa que dicha relación existió, es decir que se cumple $h_1$).\n",
    "\n",
    "* En nuestro caso, true positive representa la correcta predicción en la existencia de la enfermedad mientras que false positive representa correctamente la predicción sobre la ausencia de la enfermedad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En nuestro ejemplo, si detectáramos varias enfermedades en el paciente y nos interesa saber $h_0$, true negative se referirá a los casos donde predecimos que el paciente no posee ninguna enfermedad y tal situación es la real; mientras que true positive se refiere a haber inferido correctamente que el paciente posee alguna enfermedad. Este enfoque se conoce como **one-vs-all**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "Una forma sencilla de evaluar el rendimiento de un algoritmo es por medio de una **confusion matrix** o **error matrix**, la cual contrasta las predicciones con los valores verdaderos, mostrando los errores TI y TII."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  0  0]\n",
      " [ 0 10  9]\n",
      " [ 0  2  5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_hat, labels=[0,1,2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formateando:\n",
    "\n",
    "|                   |            |        |Clase estimada |           |\n",
    "|-------------------|------------|:------:|:-------------:|:---------:|\n",
    "|                   |            | Setosa |   Versicolor  | Virginica |\n",
    "|                   | Setosa     | **14** |        0      |     0     |\n",
    "|**Clase verdadera**| Versicolor |    0   |      **10**   |     7     |\n",
    "|                   | Virginica  |    0   |        6      |   **8**   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En el caso de la **clasificación muticlase**, para algunos algoritmos se usa la estrategia \"one-vs-all\" para referirse a los tipos de errores. Es decir que cada tipo de error es calculado para cada una de las clases, tomando un label de dicha clase como positivo ($y=1$) y un label de cualquier otra clase como negativo ($y=0$). \n",
    "\n",
    "* Ejemplo: clasificación multiclase desde las setosas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                   |                    |     Clase estimada      |                            |\n",
    "|-------------------|--------------------|:-----------------------:|:--------------------------:|\n",
    "|                   |                    | No Setosa ($\\hat{y}=0$) |    Setosa ($\\hat{y}=1$)    |\n",
    "|                   | No Setosa ($y=0$)  |       **31**            |             0              |\n",
    "|**Clase verdadera**| Setosa    ($y=1$)  |          0              |          **14**            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Esto se hace para poder extender el problema a partir de una clasificación binaria, pudiendo evaluar los errores TI y TII de la misma forma.\n",
    "\n",
    "* Vemos ahora con mejor nivel de detalle aspectos como que las 14 flores Setosa utilizadas para el test fueron correctamente clasificadas, mientras que las flores Versicolor se confunden frecuentemente con las Virginica.\n",
    "\n",
    "Vamos a procesar todavía más esta información al calcular métricas adicionales que nos permitirán obtener más claridad.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vista general: de todos los puntos (representada por un rectángulo, que divide los positivos de los negativos) elegimos una determinada cantidad de puntos como positivos (representada por el círculo central)\n",
    "\n",
    "![Positives - Negatives](images/positives_negatives.png)\n",
    "\n",
    "Fuente: Walber (usuario de Wikipedia), imagen adaptada desde https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concepto preliminar: en la clasificación binaria, es decir aquellos problemas donde $c_i \\in \\{False, True\\}$, el **umbral** o _threshold_ $\\theta \\in [0,1]$ es la probabilidad mínima que hace que el predictor clasifique una observación como True. Aquellas probabilidades por debajo del umbral son clasificadas como False.\n",
    "\n",
    "Por ejemplo, un $\\theta = 0.75$ hace necesario que $P(y=1 \\mid x) > 0.75$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas desde el punto de vista de los negativos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "La primera métrica es el **false positive rate (FPR)** (o proporción de falsas alarmas), que representa el porcentaje de errores de TI en la clasificación, es decir\n",
    "\n",
    "$$ FPR = \\frac{FP}{\\text{actual negatives}} = \\frac{FP}{FP + TN}$$\n",
    "\n",
    "Un predictor no tendría falsas alarmas si se clasificara todo como \"False\", al usar un umbral $\\theta=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte, el **false negative rate (FNR)** (o proporción de detecciones perdidas) representa el porcentaje de errores TII en la clasificación, es decir\n",
    "\n",
    "$$ FNR = \\frac{FN}{\\text{actual positives}} = \\frac{FN}{FN + TP}$$\n",
    "\n",
    "Un predictor no tendría detecciones perdidas si clasificara todo como \"True\", usando un umbral $\\theta = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas desde el punto de vista de los positivos\n",
    "\n",
    "![](images/precision_recall.png)\n",
    "\n",
    "Fuente: Walber (usuario de Wikipedia), imagen adaptada desde https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los indicadores principales es el **positive predictive value** o **precision**, que representa el porcentaje de positivos correctamente inferidos como tal por cada positivo inferido. Está dado por\n",
    "\n",
    "$$P(y=1 \\mid \\hat{y}=1) = \\frac{TP}{\\text{predicted positives}} = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "Intuitivamente puede interpretarse como **\"qué tan seguro es un clasificador al inferir las observaciones como positivas\"**. Un predictor maximizaría esta métrica si clasificara como \"True\" sólo aquellas observaciones con las que cuente con total certeza que son \"True\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro indicador principal es el **true positive rate**, **sensitivity** o **recall**, que representa el porcentaje de positivos correctamente inferidos por cada positivo real, dado por\n",
    "\n",
    "$$P(\\hat{y}=1 \\mid y=1)= \\frac{TP}{\\text{actual positives}} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "Intuitivamente puede interpretarse como **\"qué tan bueno es un clasificador en detectar los positivos\"**. Un predictor sería perfecto en la detección de positivos si clasificara todo como \"True\", al usar un umbral $\\theta = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análogamente, el **true negative rate** o **specificity** es similar al recall pero considerando los negativos, es decir\n",
    "\n",
    "$$P(\\hat{y}=0 \\mid y=0)= \\frac{TN}{\\text{actual negatives}} = \\frac{TN}{TN + FP}$$\n",
    "\n",
    "Intuitivamente puede interpretarse como \"qué tan bueno es un clasificador evitando las falsas alarmas\". Como vimos antes, un predictor sería perfecto en evitar falsas alarmas si clasificara todo como \"False\", es decir usara un $\\theta=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera medida que venimos usando, el porcentaje de aciertos (**accuracy**) está dada por\n",
    "\n",
    "$$\\text{accuracy} = \\frac{\\text{correctly predicted}}{\\text{all predicted}} = \\frac{TP + TN}{TP + FP + TN + FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es trivial y poco útil maximizar precision o recall por separado, un buen clasificador debería, en general (y dependiendo del problema que trata de resolver), intentar maximizar conjuntamente tanto precision como recall. Normalmente ambos representan intereses contrapuestos.\n",
    "\n",
    "* Considerar como ejemplo la extracción de un tumor cerebral, donde un cirujano debe intentar maximizar la cantidad de células cancerígenas extraídas (recall) para evitar que se regenere el tumor, minimizando a su vez la cantidad de células no cancerígenas extraídas (precision) que podrían afectar las funciones cerebrales.\n",
    "\n",
    "* Debido a que ambas métricas van de la mano, para evaluarlas conjuntamente se suele usar el F1 score, dado por la media armónica\n",
    "\n",
    "$$f_1 = \\frac{2}{P^{-1}+R^{-1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn convenientemente hace este procesamiento por nosotros, como vemos a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       0.83      0.53      0.65        19\n",
      "   virginica       0.36      0.71      0.48         7\n",
      "\n",
      "   micro avg       0.76      0.76      0.76        45\n",
      "   macro avg       0.73      0.75      0.71        45\n",
      "weighted avg       0.83      0.76      0.77        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_hat, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que _support_ es la cantidad de instancias (true values) de cada una de las clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False positive vs false negative tradeoff\n",
    "\n",
    "Como acabamos de ver, la contraposición de intereses en un clasificador se da porque existe una relación inversa entre los errores false positive (falsa alarma) y los errores false negative (detección perdida).\n",
    "\n",
    "* La inclinación que querramos darle a este tradeoff depende del problema que estemos intentando resolver.\n",
    "\n",
    "* Para aquellas tareas que se desempeñan en entornos con aversión al riesgo, como vemos en el ejemplo de la cirugía cerebral, debemos diseñar nuestro clasificador de tal forma que se minimicen los costos totales producidos por los errores de predicción.\n",
    "\n",
    "* En la clasificación binaria, una de las opciones es incluir una **reject region**, es decir un umbral de probabilidad donde el predictor, en lugar de clasificar como False, no tomará decisiones, dejando las mismas en manos de una persona, por ejemplo.\n",
    "\n",
    "![](images/reject_region.png)\n",
    "\n",
    "Fuente: Figura 1.26 de Bishop 2006a (nota: no confundir $\\theta$ utilizado en la figura y en el notebook para denotar un umbral con $\\theta$ comúnmente utilizado para referirse a los híper-parámetros del predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativamente, si queremos tomar esa decisión pero que nuestro clasificador sea conservador debido al posible costo de los errores, podemos usar el mismo umbral para definir hasta cuánto debe ser nuestro grado de seguridad para asegurar o rechazar $h_0$.\n",
    "\n",
    "* En los clasificadores probabilísticos vistos aquí, el umbral es establecido al ver la probabilidad de predicción de as distintas clases, y alterando la clase elegida cuando la misma no supera el umbral.\n",
    "\n",
    "* Por defecto, el umbral utilizado en los clasificadores binarios es $\\theta=0.5$, mientras que en los clasificadores multi-clase se selecciona la clase para la cuál nuestro clasificador arroja mayor probabilidad.\n",
    "\n",
    "* Veamos las probabilidades de nuestro kNN para el dataset iris..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  0.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.2 0.8]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.4 0.6]\n",
      " [0.  0.4 0.6]\n",
      " [1.  0.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [1.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict_proba(X_test[:10,:])) \n",
    "\n",
    "# cada una de las columnas de salida representa la probabilidad estimada por el clasificador \n",
    "# para cada una de las clases, para las primeras 10 filas de datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No obstante, en determinadas situaciones es deseable cambiar el umbral, por ejemplo...\n",
    "\n",
    "1. Deseamos testear la certeza con la que nuestro clasificador toma las decisiones.\n",
    "2. Los errores FP y FN tienen una incidencia distinta en el problema para el cuál utilizamos el clasificador, para lo cuál es necesario cambiar $\\theta$ en consecuencia.\n",
    "\n",
    "Analizamos el primer caso. El segundo caso se encuentra analizado en el [Material Extra](https://github.com/inteligenciafrvm/inteligenciafrvm/blob/master/Material%20Extra/Clasificaci%C3%B3n%20II%20-%20Minimizar%20error%20cambiando%20umbrales/Clasificaci%C3%B3n%20II%20-%20Minimizar%20error%20cambiando%20umbrales.ipynb):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1\\. Deseamos testear la certeza con la que nuestro clasificador toma las decisiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiver operating characteristic (ROC) curve\n",
    "\n",
    "* Los umbrales también pueden utilizarse para evaluar la _certeza_ de nuestro clasificador, es decir con qué margen de confianza infiere la clase de cada una de las observaciones, para de esta manera poder compararlo mejor frente a otros clasificadores en cuanto a su capacidad de generalizar.\n",
    "\n",
    "* Por ejemplo, el clasificador A y el clasificador B pueden tener idénticas predicciones para un dataset, pero A estar clasificando a todas las clases con un 95% de probabilidad y B estar clasificando con un 51%.\n",
    "\n",
    "* Distinguir entre ambos clasificadores es precisamente la idea de las curvas ROC. En ellas se muestra cómo se comparan los distintos clasificadores en términos de TPR y FPR con respecto a la suposición aleatoria (elige clase 0 o 1 aleatoriamente) y al clasificador perfecto, mostrando el equilibrio entre true positives y false positives para las distintas instancias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Veamos cómo se ve una curva ROC para nuestro ejemplo (armado a partir de https://github.com/reiinakano/scikit-plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instalamos la dependencia requerida\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "try: # try usado porque la invocación de pip cambia según la versión del mismo\n",
    "    from pip import main as pipmain # pip 9\n",
    "except:\n",
    "    from pip._internal import main as pipmain # pip 10\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "pipmain([\"install\", \"scikit-plot\"])\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scikitplot as skplt\n",
    "\n",
    "y_hat_probas = clf.predict_proba(X_test)\n",
    "\n",
    "# predicted probabilities generated by sklearn classifier\n",
    "# Notar que micro-average ROC curve es el promedio de las áreas de las curvas ROC, \n",
    "# mientras que macro-average ROC curve es el mismo promedio pero ponderado por la \n",
    "# cantidad de observaciones de cada clase.\n",
    "skplt.metrics.plot_roc(y_test, y_hat_probas, plot_micro=False, plot_macro=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para comparar la calidad de las curvas ROC, una medida utilizada es comparar su área bajo la curva de cada clasificador.\n",
    "\n",
    "* Notar que cualquier clasificador puede alcanzar el límite inferior izquierdo (TPR=FPR=0) al setear $\\theta=1$ y por lo tanto clasificar todo como 0. Análogamente, setear $\\theta=0$ hará que todos los resultados sean clasificados como 1, obteniendo (TPR=FPR=1).\n",
    "\n",
    "* Trazar una línea (TPR=FPR) muestra cómo se desempeña el clasificador aleatorio, el cual es el piso mínimo que todo clasificador debe superar.\n",
    "\n",
    "* Para medir la perfomance de los clasificadores de acuerdo a sus curvas ROC, el criterio utilizado es el de calcular el área bajo la curva ROC (número real que va de 0 a 1). Esta, junto con precision, recall, f1 y la tasa de aciertos, es otra métrica muy útil para evaluar el rendimiento de nuestro clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver solamente la métrica del AUC de la curva ROC (es decir no mostrar la curva) se puede usar esta librería (sólo para clasificación binaria):\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajo Práctico 4\n",
    "\n",
    "Utilizando un dataset de Kaggle o de su elección para clasificación, realizar la mejora iterativa de un modelo de clasificación para dicho dataset. Realizar un informe (estilo bitácora, puede ser un notebook, un pdf/doc o incluso estar junto con el código) en donde se especifiquen las distintas etapas de iteración del mismo, y se citen las fuentes consultadas. Las consignas son las siguientes:\n",
    "\n",
    "[ ] Realizar submission(s) a Kaggle y especificar cuáles fueron los puntajes en la tabla de posiciones tras la(s) submission(s) (no aplica para datasets fuera de Kaggle, en los cuáles deberá especificarse la métrica alcanzada).\n",
    "\n",
    "[ ] Realizar algún tipo de normalización en los datos. Decidir si la misma es incluída (o no) en el modelo, y justificar brevemente por qué.\n",
    "\n",
    "[ ] Especificar el pre-procesamiento adicional que fue realizado en los datos (si aplica).\n",
    "\n",
    "[ ] Mostrar métricas de tasa de aciertos, precision y recall.\n",
    "\n",
    "[ ] Utilizar modelo(s) de clasificación más flexible(s) que kNN.\n",
    "\n",
    "[ ] Validar distintos híper-parámetros para dicho modelo. Esto puede ser realizado informalmente o con algún método tipo grid-search.\n",
    "\n",
    "[ ] Realizar PCA y ver cómo es explicada la varianza por sus componentes principales. Decidir si PCA es incluido en el modelo o no, y justificar brevemente el motivo de esta decisión.\n",
    "\n",
    "El puntaje por ejercicios básicos, complementarios y extra se encuentra dentro de las consignas especificadas. Se alienta a que jueguen con distintos datos y modelos, prueben alternativas, y traten de mejorar su puntaje en el ranking lo más que puedan. Se propone debajo código para un procesamiento inicial del dataset Titanic, no obstante se alienta a quienes quieran explorar otros datasets, o incluso propios!\n",
    "\n",
    "Fecha de entrega: **06/06/2019 23:59**.\n",
    "\n",
    "Se permite realizar el trabajo en grupos de dos. La reutilización del código del notebook está permitida (por ejemplo para confeccionar gráficos).\n",
    "\n",
    "Nota: Existen muchos kernels online que establecen cómo resolver los datasets de los concursos. Si bien se alienta a ver otras formas de resolver problemas, esto no debe ir en detrimento del requisito de originalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info adicional\n",
    "\n",
    "1. Nueva modalidad de Examen Final Práctico, disponible a partir de Julio 2019: presentación individual de trabajos prácticos 4 y 5.\n",
    "\n",
    "2. Eventos de AI de 2019:\n",
    "\n",
    "    * [Escuela de Ciencias Informáticas](https://eci2019.dc.uba.ar/). Cursos interesantes de IA: aprendizaje profundo por refuerzo, clasificadores probabilísticos en aprendizaje automático, procesamiento del lenguaje natural con redes neuronales.\n",
    "    * [Khipu - Latin American Meeting In Artificial Intelligence](https://khipu.ai/index.html). Encuentro con talleres y charlas sobre IA.\n",
    "    * [PyData Córdoba 2019](https://pydata.org/cordoba2019/). Encuentro con charlas sobre casos de estudio aplicados en ML/data science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# codigo de ejemplo para leer y hacer transformaciones basicas en un dataset \n",
    "# (mas info en https://www.kaggle.com/c/titanic/data)\n",
    "\n",
    "# pandas es una gran libreria para manejo de sets de datos grandes\n",
    "import pandas as pd  \n",
    "\n",
    "# importamos los datos del csv como dataframe\n",
    "df = pd.read_csv('data/train.csv')  # dataframe descargado de https://www.kaggle.com/c/titanic/data\n",
    "# (si quisieramos guardar a un csv (por ejemplo para hacer la submission), el procedimiento es similar,\n",
    "# es decir df.to_csv('<path>'))\n",
    "\n",
    "# vemos las primeras 5 columnas\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# vemos las columnas del dataset\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vemos una descripción general del dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005007</td>\n",
       "      <td>-0.035144</td>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.012658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>-0.005007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.035144</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.096067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PassengerId  Survived    Pclass       Age     SibSp     Parch  \\\n",
       "PassengerId     1.000000 -0.005007 -0.035144  0.036847 -0.057527 -0.001652   \n",
       "Survived       -0.005007  1.000000 -0.338481 -0.077221 -0.035322  0.081629   \n",
       "Pclass         -0.035144 -0.338481  1.000000 -0.369226  0.083081  0.018443   \n",
       "Age             0.036847 -0.077221 -0.369226  1.000000 -0.308247 -0.189119   \n",
       "SibSp          -0.057527 -0.035322  0.083081 -0.308247  1.000000  0.414838   \n",
       "Parch          -0.001652  0.081629  0.018443 -0.189119  0.414838  1.000000   \n",
       "Fare            0.012658  0.257307 -0.549500  0.096067  0.159651  0.216225   \n",
       "\n",
       "                 Fare  \n",
       "PassengerId  0.012658  \n",
       "Survived     0.257307  \n",
       "Pclass      -0.549500  \n",
       "Age          0.096067  \n",
       "SibSp        0.159651  \n",
       "Parch        0.216225  \n",
       "Fare         1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vemos la correlación de las variables del dataset\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este análisis es muy interesante para entender cómo cambian pares de features en tándem. Recordar que [correlación no implica causalidad](https://xkcd.com/1122/). Si bien es un buen indicio para explorar una hipótesis, la misma debería ser validada o refutada por otros medios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformamos el dataframe en matriz de datos\n",
    "\n",
    "#  'loc' en un dataframe permite obtener datos de forma similar a las listas en\n",
    "# python y numpy, con la diferencia de que las posiciones de las mismas son llamadas\n",
    "# por medio de los nombres de las columnas, y la posición final *sí* es incluida\n",
    "X = df.loc[:, df.columns != 'Survived'].values\n",
    "y = df['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 'Braund, Mr. Owen Harris' ... 7.25 nan 'S']\n",
      " [2 1 'Cumings, Mrs. John Bradley (Florence Briggs Thayer)' ... 71.2833\n",
      "  'C85' 'C']\n",
      " [3 3 'Heikkinen, Miss. Laina' ... 7.925 nan 'S']\n",
      " ...\n",
      " [889 3 'Johnston, Miss. Catherine Helen \"Carrie\"' ... 23.45 nan 'S']\n",
      " [890 1 'Behr, Mr. Karl Howell' ... 30.0 'C148' 'C']\n",
      " [891 3 'Dooley, Mr. Patrick' ... 7.75 nan 'Q']]\n"
     ]
    }
   ],
   "source": [
    "# vemos la matriz de datos X\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# vemos el vector *y* de las primeras 20 salidas\n",
    "print(y[:20])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
