## Introducción a la Inteligencia Artificial (enfoque práctico)

### Repaso: definición / perspectiva de la IA (Russel y Norvig, 2010)

* Pensar ("caja blanca")
    * Como humanos: Enfoque cognitivo, neurocientífico, psicológico.
    * Racionalmente: Razonamiento lógico, deducciones a través de su conocimiento.


* Actuar ("caja negra")
    * Como humanos: Test de Turing.
    * Racionalmente: Agente racional, actúa buscando el mejor resultado.

![Definiciones de IA](images/1/cuadrante_ia.png)

* Estas perspectivas no son simplemente formas de definir la IA, sino que marcan una separación entre distintas posturas en las comunidades científicas.
	* Ejemplo claro de postura: [The Bitter Lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html), de Richard Sutton. 

### Repaso: inteligencia artificial general (AGI) (Russel y Norvig, 2010)

* IA universal capaz de aprender y actuar en cualquier ambiente.


* Llegar a la AGI es el **Pináculo de la IA**. También referido como "Strong AI" (computadora con una mente, capaz de entender, imposible que exista según filósofos como [Searle](https://es.wikipedia.org/wiki/Habitaci%C3%B3n_china)).

Hasta ahora, la única formalización teórica-matemática sobre la misma es [AIXI](https://en.wikipedia.org/wiki/AIXI), propuesta por Marcus Hutter, Jürgen Schmidhuber y Shane Legg.

### Estado actual de la IA:

* ¿"Verano de la IA"? grandes recursos computacionales + grandes datasets + grandes algoritmos.


* Grandes avances en procesamiento de imágenes, audio, video y texto.


* Aplicaciones impresionantes en robótica y juegos.


* Integración de IA en industrias y áreas de investigación no necesariamente relacionadas con computación.


* Enfoque *bottom-up* (inductivo, a partir de los datos "crudos") de la IA actualmente se impone frente al enfoque *top-down* (deductivo, a partir de modelos cognitivos o del razonamiento lógico).


* Dominio del aprendizaje automático (*machine learning (ML)*), auge del **deep learning** (DL).

Ejemplo 1: Reconocimiento de imágenes

![Reconocimiento de imágenes](images/1/imagenet.png)
(crédito: https://www.cs.toronto.edu/~fritz/absps/imagenet.pdf)

Ejemplo 2: Decodificación de videos

https://youtu.be/nsjDnYxJ0bo

https://www.youtube.com/watch?v=Qh5_uMGXl1g

(crédito: http://www.purdue.edu/newsroom/releases/2017/Q4/researchers-demonstrate-mind-reading-brain-decoding-tech-----.html)

Ejemplo 3: Generación de imágenes "reales"!!!

![Generación de imágenes "reales"](images/1/gan_examples.png)

(crédito:  Nguyen et al. 2016 - Plug & play generative networks:  Conditional iterative generation of images
in latent space - https://arxiv.org/abs/1612.00005)

[También de personas hablando en un video!](https://www.youtube.com/watch?v=p1b5aiTrGzY&feature=youtu.be)

(crédito: [Paper de 2019 de Samsung AI: Few-Shot Adversarial Learning of Realistic Neural Talking Head Models](https://www.profillic.com/paper/arxiv:1905.08233))


### Estado actual de la IA: algunos desafíos (funcionales)

El enfoque funcional adoptado para llevar a cabo inducciones presenta varios desafíos

* Tendencia a usar modelos de caja negra, poco interpretables.


* Sensibilidad a la distribución del dominio / datos con los que fueron entrenaron los modelos.


* Ajuste de híper-parámetros.


* ¿Cómo integrar conocimiento de dominio?

Ejemplo 1:

http://www.labsix.org/media/2017/10/31/video.mp4

(crédito: http://www.labsix.org/physical-objects-that-fool-neural-nets/)

Ejemplo 2

![Obama](images/1/obama_funny.jpg)

(crédito: https://karpathy.github.io/2012/10/22/state-of-computer-vision/)

### Estado actual de la IA: algunos desafíos (ingenieriles)

Se requiere **mucho esfuerzo para preparar los datos** y que puedan servir como entradas en modelos de IA. Buena lectura: https://www.oreilly.com/radar/the-unreasonable-importance-of-data-preparation/. ¿Y los datos del Coronavirus? [Buena lectura sobre dificultad con estos datos](https://fivethirtyeight.com/features/why-its-so-freaking-hard-to-make-a-good-covid-19-model/).

![Pirámide](images/1/data_preparation_pyramid.png)
Fuente: https://www.oreilly.com/radar/the-unreasonable-importance-of-data-preparation/

***

### Estado actual de la IA: algunos desafíos (éticos)

#### Varias posturas populares con respecto al estado actual y futuro de la IA


##### Actualidad:

* **IA promisoria** como herramienta fundamental en nuestras vidas
    * La posibilidad de replicar capacidades humanas abre las puertas a posibilidades sin precedentes.
    * Gran capacidad de resolver problemas mediante automatización.
    * Capacidad de obtener información muy valiosa en los enormes volúmenes de datos que generamos.
    * Capacidad de detectar tempranamente problemas como los de salud y asociaciones/patrones ocultos.

vs.

* **Miedo** de las capacidades de la IA
    * Capacidad de quitarnos trabajos y de empeorar la distribución global de la riqueza.
    * Modelos replican sesgos en la sociedad (racismo, xenofobia, discriminación, etc.) y permite manipulación de los mismos.
    * La falta de comprensión sobre los modelos con impacto real en nuestras vidas puede generar consecuencias que llegan desde accidentes hasta catástrofes naturales.
    * El usuario no tiene un acceso transparente de cómo y para qué se usan sus datos (en ocasiones directamente no puede ver ni qué tipo de datos recolectan de él) que sirven para entrenar modelos, ni qué información se infiere en base a los mismos > Muchas aplicaciones se aprovechan de esto para extraer información sin consentimiento. Ejemplo: recordar lo que pasó con Cambridge Analytica. Película sobre esto: The Social Dilemma (en Netflix).


> But as Cathy O’Neil reveals in this urgent and necessary book, the opposite is true. The models being used today are **opaque**, **unregulated**, and **uncontestable**, even when they’re wrong.
Most troubling, they reinforce discrimination: If a poor student can’t get a loan because a lending model deems him too risky (by virtue of his zip code), he’s then cut off from the kind of education that could pull him out of poverty, and a vicious spiral ensues. Models are propping up the lucky and punishing the downtrodden, creating a “toxic cocktail for democracy.” Welcome to the dark side of Big Data.
Tracing the arc of a person’s life, O’Neil exposes the black box models that shape our future, both as individuals and as a society. These “weapons of math destruction” score teachers and students, sort résumés, grant (or deny) loans, evaluate workers, target voters, set parole, and monitor our health.


##### A futuro:

* Estamos a muchos, muchos años de resolver la Inteligencia Artificial General (AGI). Ejemplo: https://www.nytimes.com/2017/07/29/opinion/sunday/artificial-intelligence-is-stuck-heres-how-to-move-it-forward.html


vs.

* IA cada vez más crucial en nuestras vidas, necesidad de regularla y tomar cartas en el asunto. Fuente: [Erdélyi y Goldsmith - Regulating Artificial Intelligence: Proposal for a Global Solution. AAAI 2018](http://www.aies-conference.com/wp-content/papers/main/AIES_2018_paper_13.pdf)


* "Carrera en la IA" (estilo "carrera espacial") para el avance estratégico: retórica y riesgos. Fuente: [Cave y Heigeartaigh - An AI Race for Strategic Advantage: Rhetoric and Risks. AAAI 2018](http://www.aies-conference.com/wp-content/papers/main/AIES_2018_paper_163.pdf)
    * Riesgos de que solamente exista una retórica: obstaculiza el debate y puede incitar a una carrera.
    * Riesgos de que existan tanto una retórica como una carrera: riesgos de no tomar medidas de seguridad adecuadas y riesgos de un conflicto entre grupos o hasta países.
    * Riesgos de que exista una carrera, sin retórica: concentración de poder y posibilidad de abusos y conflictos.

 ¿Qué hacer entonces? (según los autores)
 * Como sociedad: "IA para todos" - democratizar el poder de la IA y sus beneficios. Datos abiertos y algoritmos transparentes. Así, no importará quién "gana" la carrera.
 * Como profesionales: **distribuir el conocimiento de la IA**; promover narrativas positivas en la sociedad y en los políticos.

vs.

* Se viene Skynet? (sensacionalismo) Ejemplo: https://www.entrepreneur.com/article/298005. Debate reciente sobre esto: https://old.reddit.com/r/MachineLearning/comments/b0rdsi/d_irresponsible_anthropomorphism_is_killing_ai/?st=jt8tr18y&sh=1e91a65b

En la actualidad, al menos dos empresas apuntan a la AGI (asumiendo a la misma como posible): DeepMind y OpenAI

   * Postura de OpenAI al decidir (y dejar públicamente sentada su decisión) de no publicar un modelo entrenado de procesamiento de texto, y subsecuentes debates https://www.skynettoday.com/briefs/gpt2, https://old.reddit.com/r/MachineLearning/comments/arpysz/d_openai_not_releasing_fully_trained_model_is_it/

   * [Interesante artículo sobre OpenAI en este aspecto](https://www.technologyreview.com/s/615181/ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality/) y [su correspondiente discusión en reddit](https://old.reddit.com/r/MachineLearning/comments/f5immz/d_the_messy_secretive_reality_behind_openais_bid/)


***


### Estado actual de la IA: oportunidad de gran aporte para el beneficio social

Dos beneficios principales de la explosión de IA/ML desde 2012:

* Potenció muchos métodos que se investigaban hace décadas: desde sencillos métodos estadísticos hasta redes neuronales.
* Aportó nuevas formas de realizar generalizaciones **sin tener que diseñar features a mano**.

Esto permitió el surgimiento de aplicaciones de todo tipo, entre las cuáles se encuentran algunas con capacidad de tener un impacto social muy positivo. Algunos ejemplos:

* Detección temprana de enfermedades.
* Mejores usos en agricultura.
* Predicciones de fenómenos climáticos, cambio climático.
* Redistribución de la riqueza.

***

### Estado actual de la IA: Área muy demandada en la industria \*:

Hay cuatro trabajos principales como profesionales

* Data engineer
* Data scientist
* Research engineer
* Research scientist

(\* estos roles, como surgieron hace pocos años, no están marcados en piedra y pueden ser más difusos/tener distinto significado según cada empresa, equipo, y volumen de información manejado)

***


```python

```
